{"componentChunkName":"component---src-templates-blog-js","path":"/e588a9e794a8jse5819ae68a93e58f96e79a84demo","result":{"data":{"blog":{"id":"fb28720d-5c1f-51dd-b273-0c1ae0540147","html":"<p>传统的爬虫模拟 http 请求获取页面没有办法模拟 ajax 请求，导致很多数据就难以获取。爬虫一直在试图把自己弄得像一个浏览器那样，可以处理各种诡异的情况。但是很遗憾，如果这个爬虫没有 js 解析的能力那怎么能够去处理 ajax 呢，如果爬虫不知道怎么渲染界面，它怎么知道什么元素是可见的，什么元素是不可见的呢。现在很多页面都是采用了前端脚本。乱七八糟的 template 里面是什么真正的数据都没有的。json 里面的东西才是有意义的内容。所以，爬虫如果想完全处理那些问题，那它就要具备很多浏览器的功能了～</p>\n<p>但是，如果反过来怎么样呢？我们其实可以就用一个真真正正的浏览器去做这些工作的呀。我们可以让一个浏览器去模拟爬虫的抓取形式。当页面 load 完成后就可以获取页面的 html 内容了 (innerHTML 这样的东西)，然后检索整个页面上的合法 Link 去一个个打开做递归...</p>\n<p>事实上，做爬虫很多时候就是想找到我们指定的一些数据。对页面里面很多乱七八糟的东西是没有兴趣的。可以只写 js 去定位一些元素里面的数据。当然，这会有很多的问题的。一个个打开，这样很慢的，效率是个问题。可是我觉得这的的确确是一个思路啊...</p>\n<p>这个控件里面是有 ajax 请求的，每次点击了一个城市，才会激发 ajax 请求获取数据。利用传统的方式，可能就要去找 ajax 的规律，然后利用规律一个个下载。但是我们用前端模拟点击事件，让页面自己按照常规的方式加载新的数据，然后从 dom 里面取到我们所需的内容就可以了</p>\n<p>这里我录了个屏，<code>录屏丢了</code>，由于尺寸比较大，就不插在文章里面了。请点击这个观看一段抓取的效果。当然，这仅仅是前端技术越发强大的冰山一角。我相信前端将会变得越发的强大以及越发的重要。</p>","tableOfContents":"","frontmatter":{"title":"利用 JS 做抓取的 demo","date":"December 07, 2011","tags":null},"excerpt":"传统的爬虫模拟 http 请求获取页面没有办法模拟 ajax 请求，导致很多数据就难以获取。爬虫一…"}},"pageContext":{"id":"fb28720d-5c1f-51dd-b273-0c1ae0540147"}},"staticQueryHashes":["4202924991"]}