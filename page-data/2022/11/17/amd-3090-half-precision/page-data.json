{"componentChunkName":"component---src-templates-blog-js","path":"/2022/11/17/amd-3090-half-precision/","result":{"data":{"blog":{"id":"5f835784-3402-51f6-ba36-a459fcf751d6","html":"<p>最近发现跑 pytorch gpu benchmark 的时候，AMD epyc cpu 下的 rtx 3090 明显要比 intel 下 3090 慢，而且差距挺大的，非常不能理解。折腾了挺长一段时间才最终定位到是因为 cpu 在容器里的调度问题导致的。过程兜兜转转花了不少时间，这里就不说太多了，记录下大体过程和最后调优的措施。</p>\n<h2 id=\"最开始的测试\" style=\"position:relative;\">最开始的测试<a href=\"#%E6%9C%80%E5%BC%80%E5%A7%8B%E7%9A%84%E6%B5%8B%E8%AF%95\" aria-label=\"最开始的测试 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<h3 id=\"测试脚本\" style=\"position:relative;\">测试脚本<a href=\"#%E6%B5%8B%E8%AF%95%E8%84%9A%E6%9C%AC\" aria-label=\"测试脚本 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<ul>\n<li>python gpu benchmark: <a href=\"https://github.com/ryujaehun/pytorch-gpu-benchmark\">https://github.com/ryujaehun/pytorch-gpu-benchmark</a></li>\n<li>model: <code>models.resnet.__all__[1:]</code> 只测试 resnet 模型</li>\n<li>batch size: 64</li>\n<li>cpu limit: 12</li>\n<li>memory limit: 30G</li>\n<li>gpu limit: 1</li>\n<li>shm: docker 给 30G 而 k8s 里由于无法直接设置，就给了机器内存的大小</li>\n</ul>\n<h3 id=\"nvidia-docker-脚本\" style=\"position:relative;\">nvidia docker 脚本<a href=\"#nvidia-docker-%E8%84%9A%E6%9C%AC\" aria-label=\"nvidia docker 脚本 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">docker</span> run --rm -it --shm-size<span class=\"token operator\">=</span>30g --cpus<span class=\"token operator\">=</span><span class=\"token number\">12</span> --memory<span class=\"token operator\">=</span>30G --\ngpus <span class=\"token string\">'\"device=1\"'</span> uhub.service.ucloud.cn/openbayesruntimes/pytorch:1.9.0-py36-cu111.70</code></pre></div>\n<h3 id=\"两个差异很大的结果\" style=\"position:relative;\">两个差异很大的结果<a href=\"#%E4%B8%A4%E4%B8%AA%E5%B7%AE%E5%BC%82%E5%BE%88%E5%A4%A7%E7%9A%84%E7%BB%93%E6%9E%9C\" aria-label=\"两个差异很大的结果 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<h4 id=\"intel-平台\" style=\"position:relative;\">Intel 平台<a href=\"#intel-%E5%B9%B3%E5%8F%B0\" aria-label=\"intel 平台 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">start\nbenchmark start : 2022/11/17 06:15:23\nNumber of GPUs on current device : 1\nCUDA Version : 11.1\nCudnn Version : 8005\nDevice Name : NVIDIA GeForce RTX 3090\nuname_result(system='Linux', node='d1d271bdf102', release='5.4.0-131-generic', version='#147-Ubuntu SMP Fri Oct 14 17:07:22 UTC 2022', machine='x86_64', processor='x86_64')\n                     scpufreq(current=1184.1902125, min=800.0, max=3400.0)\n                    cpu_count: 80\n                    memory_available: 258789797888\nBenchmarking Training half precision type resnet18\n/usr/local/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\nresnet18 model average train time : 41.39636039733887ms\nBenchmarking Training half precision type resnet34\nresnet34 model average train time : 55.32251834869385ms\nBenchmarking Training half precision type resnet50\nresnet50 model average train time : 92.97645568847656ms\nBenchmarking Training half precision type resnet101\nresnet101 model average train time : 147.91772842407227ms\nBenchmarking Training half precision type resnet152\nresnet152 model average train time : 209.90628242492676ms\nBenchmarking Training half precision type resnext50_32x4d\nresnext50_32x4d model average train time : 132.71542072296143ms\nBenchmarking Training half precision type resnext101_32x8d\nresnext101_32x8d model average train time : 336.4134645462036ms\nBenchmarking Training half precision type wide_resnet50_2\nwide_resnet50_2 model average train time : 156.14235401153564ms\nBenchmarking Training half precision type wide_resnet101_2\nwide_resnet101_2 model average train time : 259.703106880188ms\nBenchmarking Inference half precision type resnet18\nresnet18 model average inference time : 31.02853298187256ms\nBenchmarking Inference half precision type resnet34\nresnet34 model average inference time : 39.35199737548828ms\nBenchmarking Inference half precision type resnet50\nresnet50 model average inference time : 41.26767635345459ms\nBenchmarking Inference half precision type resnet101\nresnet101 model average inference time : 48.41951370239258ms\nBenchmarking Inference half precision type resnet152\nresnet152 model average inference time : 67.41719722747803ms\nBenchmarking Inference half precision type resnext50_32x4d\nresnext50_32x4d model average inference time : 44.739885330200195ms\nBenchmarking Inference half precision type resnext101_32x8d\nresnext101_32x8d model average inference time : 103.05868148803711ms\nBenchmarking Inference half precision type wide_resnet50_2\nwide_resnet50_2 model average inference time : 49.078497886657715ms\nBenchmarking Inference half precision type wide_resnet101_2\nwide_resnet101_2 model average inference time : 83.67201805114746ms\nbenchmark end : 2022/11/17 06:21:41\nend</code></pre></div>\n<h4 id=\"amd-平台\" style=\"position:relative;\">AMD 平台<a href=\"#amd-%E5%B9%B3%E5%8F%B0\" aria-label=\"amd 平台 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">start\nbenchmark start : 2022/11/17 06:14:11\nNumber of GPUs on current device : 1\nCUDA Version : 11.1\nCudnn Version : 8005\nDevice Name : NVIDIA GeForce RTX 3090\nuname_result(system='Linux', node='925b73b78805', release='5.15.0-43-generic', version='#46-Ubuntu SMP Tue Jul 12 10:30:17 UTC 2022', machine='x86_64', processor='x86_64')\n                     scpufreq(current=2784.047382812501, min=1500.0, max=2200.0)\n                    cpu_count: 256\n                    memory_available: 485026041856\nBenchmarking Training half precision type resnet18\n/usr/local/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\nresnet18 model average train time : 75.70790767669678ms\nBenchmarking Training half precision type resnet34\nresnet34 model average train time : 82.6269006729126ms\nBenchmarking Training half precision type resnet50\nresnet50 model average train time : 111.1276912689209ms\nBenchmarking Training half precision type resnet101\nresnet101 model average train time : 161.16506576538086ms\nBenchmarking Training half precision type resnet152\nresnet152 model average train time : 228.9912509918213ms\nBenchmarking Training half precision type resnext50_32x4d\nresnext50_32x4d model average train time : 143.40569496154785ms\nBenchmarking Training half precision type resnext101_32x8d\nresnext101_32x8d model average train time : 354.08830165863037ms\nBenchmarking Training half precision type wide_resnet50_2\nwide_resnet50_2 model average train time : 164.76832389831543ms\nBenchmarking Training half precision type wide_resnet101_2\nwide_resnet101_2 model average train time : 271.076135635376ms\nBenchmarking Inference half precision type resnet18\nresnet18 model average inference time : 63.87866973876953ms\nBenchmarking Inference half precision type resnet34\nresnet34 model average inference time : 68.00977230072021ms\nBenchmarking Inference half precision type resnet50\nresnet50 model average inference time : 73.05157661437988ms\nBenchmarking Inference half precision type resnet101\nresnet101 model average inference time : 81.68745994567871ms\nBenchmarking Inference half precision type resnet152\nresnet152 model average inference time : 87.46984004974365ms\nBenchmarking Inference half precision type resnext50_32x4d\nresnext50_32x4d model average inference time : 83.56608867645264ms\nBenchmarking Inference half precision type resnext101_32x8d\nresnext101_32x8d model average inference time : 108.2996940612793ms\nBenchmarking Inference half precision type wide_resnet50_2\nwide_resnet50_2 model average inference time : 78.30146789550781ms\nBenchmarking Inference half precision type wide_resnet101_2\nwide_resnet101_2 model average inference time : 90.06356239318848ms\nbenchmark end : 2022/11/17 06:23:29\nend</code></pre></div>\n<p>可以看到，越小的模型性能差异越大，这里就让我非常怀疑是 cpu 的问题。</p>\n<h2 id=\"关注主频\" style=\"position:relative;\">关注主频<a href=\"#%E5%85%B3%E6%B3%A8%E4%B8%BB%E9%A2%91\" aria-label=\"关注主频 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<p>这里 AMD 的 cpu 是 <a href=\"https://www.amd.com/en/products/cpu/amd-epyc-7773x\">7773x</a> ，64 核心，128 线程，看起来是个 monster 可是这种超多核心的服务器 cpu 的主频相对都低一些，比如这个 Base Clock 是 2.2GHz，Boost Clock 是 3.5GHz。和 Intel 平台的比，差了一点点（那边是 3.8GHz）但这不足以引起如此大的性能差异，同时在通过 <code>cat /proc/cpuinfo</code> 命令查看运行时的主频后也确认很多核心的主频都可以跑到 3.4GHz 的水平，说明没有什么诡异的 BIOS 配置限制了性能的发挥。所以主频不是导致性能差的罪魁祸首。</p>\n<h2 id=\"继续翻阅-amd-的-cpu-调优手册\" style=\"position:relative;\">继续翻阅 AMD 的 CPU 调优手册<a href=\"#%E7%BB%A7%E7%BB%AD%E7%BF%BB%E9%98%85-amd-%E7%9A%84-cpu-%E8%B0%83%E4%BC%98%E6%89%8B%E5%86%8C\" aria-label=\"继续翻阅 amd 的 cpu 调优手册 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<p>虽然主频没问题，但还是觉得 cpu 哪里不太对，于是开始在 bios 里翻各种配置项目，越翻越懵逼，看不懂那些项目什么意思，就只能通过搜索引擎找到 AMD EPYC CPU 的配置手册，不经意间看到一个 <a href=\"https://www.amd.com/system/files/documents/container-tuning-guide-kubernetes-amd-epyc7003-series-processors.pdf\">Kubernetes Container Tuning Guide for AMD EPYC 7003 Series Processors</a> 这不就是我目前所需要的？在 3.2 Container Pinning Settings 这部分提到默认的调度规则是在所有的 cpu 上做调度：</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/decdc5e60d0d898f78237884f3840635/dc333/container-pinning-settings.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 42.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAABhUlEQVQoz6WRX4vaQBTF8/2/ig/rQ/MkokZQi6tRmlYTNclk8s+ZZKLVtZvEcsqd4rLsQl964ccZuHDunXONn79e8do0WMYp5lECO06x4AkWPMVXxjHc+XBzgd9ti7quUdcNmqZB27Za33O/32H82GwQBAGel0s4mw3c/R5bz4Pn+/i+3SLgHFIpKKVQFIVWKQXKskRRSAghIaXUvevLCwwhJaQQiDlHGAQIwwCHw0G/szSFKktEjCFNU1SVwu12w7/KmM/nsG0bS9vGYvGM2WyG9XqN1WqFb44Dx3F0n9TzPOz3BzAW6l+9h5YQQsDodDrodrt4eurCNL/ANE30ej0Mh0MMBgOtljXS79FohH6/r7EsC9PpFJPJROt4PMZut4NB7owx+L6POI5xPB6RZdknkiTR+siLMqyq6g3K9nq9wsiyXJu5rqsn0LfImDLL81xDQ0jJ6HFNuvJH9JU554iiCCFjWmkTMiQlHhs9IPOPUHY08Hw+wzidTn/XVwqXywX/W38AW6uW7/q11S4AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"container pinning settings\"\n        title=\"container pinning settings\"\n        src=\"/static/decdc5e60d0d898f78237884f3840635/5a190/container-pinning-settings.png\"\n        srcset=\"/static/decdc5e60d0d898f78237884f3840635/772e8/container-pinning-settings.png 200w,\n/static/decdc5e60d0d898f78237884f3840635/e17e5/container-pinning-settings.png 400w,\n/static/decdc5e60d0d898f78237884f3840635/5a190/container-pinning-settings.png 800w,\n/static/decdc5e60d0d898f78237884f3840635/dc333/container-pinning-settings.png 938w\"\n        sizes=\"(max-width: 800px) 100vw, 800px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>那对于这个双路一共 256 线程的机器来说，调度频繁切换应该会是一个很大的开销吧？这里提到的 <code>static</code> 则是说只在特定的 cpu 里做调度。按照这个关键信息，我翻阅了 <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/\"></a> 知道了 <code>static</code> 规则用的就是 <code>cgroup</code> 的 <code>cpuset</code> 系统。那我是不是可以先用 <code>docker</code> 试试看？</p>\n<h2 id=\"使用-cpuset-命令测试\" style=\"position:relative;\">使用 cpuset 命令测试<a href=\"#%E4%BD%BF%E7%94%A8-cpuset-%E5%91%BD%E4%BB%A4%E6%B5%8B%E8%AF%95\" aria-label=\"使用 cpuset 命令测试 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">docker run --rm -it --shm-size=30g --cpuset-cpus 4-15 --cpus=12 --memory=30G --\ngpus '\"device=1\"' uhub.service.ucloud.cn/openbayesruntimes/pytorch:1.9.0-py36-cu111.70</code></pre></div>\n<p>这里就是增加了 <code>--cpuset-cpus 4-15</code> 告知 <code>docker</code> 这个容器的可用 cpu 的区间。结果发现性能有了很大的提升，实际速度也超过了 Intel 平台。那么这里就大体确定了是默认调度规则的问题了。</p>\n<h2 id=\"解决-nvidia-docker-与-cpu-调度策略冲突的问题\" style=\"position:relative;\">解决 nvidia-docker 与 cpu 调度策略冲突的问题<a href=\"#%E8%A7%A3%E5%86%B3-nvidia-docker-%E4%B8%8E-cpu-%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E5%86%B2%E7%AA%81%E7%9A%84%E9%97%AE%E9%A2%98\" aria-label=\"解决 nvidia docker 与 cpu 调度策略冲突的问题 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<p>按照 <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/\">Changing the CPU Manager Policy</a> 我很快对一台机器进行了调整，并准备在 k8s 平台上再做一次 benchmark 结果发现使用 <code>nvidia-smi</code> 命令查看显卡信息的时候报错了：</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Failed to initialize NVML: Unknown Error</code></pre></div>\n<p>又是一番查询，发现是刚刚使用的 <code>cpu-manager-polcy=static</code> 会和 nvidia-docker 有冲突：容器因为 <code>static</code> 的调度规则必须修改容器的运行时，而这种行为是 nvidia docker 所不支持的。目前的解决方式是<strong>让所有调度 gpu 的 Pod 都必须具备 <a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/\">Guaranteed 级别的 QoS</a>，同时所有的容器都必须有整数个的 cpu limitation</strong>。对于这种 Pod kubelet 会特殊对待，跳过对其 cpuset 进行更新（因为它锁定了 cpuset 所以按理说也不用更新）。同时这个支持也是在 k8s 1.22 版本之后才支持的。为此我们的集群也不得不升级到了 1.22 版本。</p>","tableOfContents":"<ul>\n<li>\n<p><a href=\"#%E6%9C%80%E5%BC%80%E5%A7%8B%E7%9A%84%E6%B5%8B%E8%AF%95\">最开始的测试</a></p>\n<ul>\n<li>\n<p><a href=\"#%E6%B5%8B%E8%AF%95%E8%84%9A%E6%9C%AC\">测试脚本</a></p>\n</li>\n<li>\n<p><a href=\"#nvidia-docker-%E8%84%9A%E6%9C%AC\">nvidia docker 脚本</a></p>\n</li>\n<li>\n<p><a href=\"#%E4%B8%A4%E4%B8%AA%E5%B7%AE%E5%BC%82%E5%BE%88%E5%A4%A7%E7%9A%84%E7%BB%93%E6%9E%9C\">两个差异很大的结果</a></p>\n<ul>\n<li><a href=\"#intel-%E5%B9%B3%E5%8F%B0\">Intel 平台</a></li>\n<li><a href=\"#amd-%E5%B9%B3%E5%8F%B0\">AMD 平台</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%E5%85%B3%E6%B3%A8%E4%B8%BB%E9%A2%91\">关注主频</a></p>\n</li>\n<li>\n<p><a href=\"#%E7%BB%A7%E7%BB%AD%E7%BF%BB%E9%98%85-amd-%E7%9A%84-cpu-%E8%B0%83%E4%BC%98%E6%89%8B%E5%86%8C\">继续翻阅 AMD 的 CPU 调优手册</a></p>\n</li>\n<li>\n<p><a href=\"#%E4%BD%BF%E7%94%A8-cpuset-%E5%91%BD%E4%BB%A4%E6%B5%8B%E8%AF%95\">使用 cpuset 命令测试</a></p>\n</li>\n<li>\n<p><a href=\"#%E8%A7%A3%E5%86%B3-nvidia-docker-%E4%B8%8E-cpu-%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E5%86%B2%E7%AA%81%E7%9A%84%E9%97%AE%E9%A2%98\">解决 nvidia-docker 与 cpu 调度策略冲突的问题</a></p>\n</li>\n</ul>","frontmatter":{"title":"记一次 k8s gpu 集群中半精度性能差异引发的系统调优","date":"November 17, 2022","tags":["k8s","gpu","容器","amd"]},"excerpt":"最近发现跑 pytorch gpu benchmark 的时候，AMD epyc cpu 下的 r…"}},"pageContext":{"id":"5f835784-3402-51f6-ba36-a459fcf751d6"}},"staticQueryHashes":["4202924991"]}