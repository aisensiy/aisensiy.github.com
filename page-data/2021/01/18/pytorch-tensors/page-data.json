{"componentChunkName":"component---src-templates-blog-js","path":"/2021/01/18/pytorch-tensors/","result":{"data":{"blog":{"id":"a5d4d343-341e-5e91-b175-13bd1fccb854","html":"<p>最近在都 Deep Learning with Pytorch 这本书，目前为止感觉还是不错。尤其是它里面的手绘风插图，真的是印象深刻，好感顿生。</p>\n<p><img src=\"https://images-1300693298.cos.ap-beijing.myqcloud.com/%7B7AD75AC9-FD58-48DE-977A-7AD6503FED3A%7D.png\" alt=\"\"></p>\n<p>第三章介绍了 tensor 的数据结构，感觉讲的挺好的，做一个笔记，加深下印象。</p>\n<h2 id=\"本质\" style=\"position:relative;\">本质<a href=\"#%E6%9C%AC%E8%B4%A8\" aria-label=\"本质 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<p>首先，tensor 感觉就和 numpy array 非常非常像，简单的讲就是多维矩阵。但是和 python 的 list 相比，tensor / numpy array 是被分配的连续内存空间。</p>\n<p><img src=\"https://images-1300693298.cos.ap-beijing.myqcloud.com/%7B8F87E9BF-4E5C-4128-9066-5610D2CB4326%7D.png\" alt=\"\"></p>\n<h2 id=\"数据类型\" style=\"position:relative;\">数据类型<a href=\"#%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B\" aria-label=\"数据类型 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<p>通过 <code>dtype</code> 参数可以指定 tensor 的数据类型。其名字和 numpy 里面的类型几乎一致：</p>\n<ul>\n<li>torch.float32 / torch.float</li>\n<li>torch.float64 / torch.double</li>\n<li>torch.float16 / torch.half</li>\n<li>torch.int8</li>\n<li>torch.unint8</li>\n<li>torch.int16 / torch.short</li>\n<li>torch.int32 / torch.int</li>\n<li>torch.int64 / torch.long</li>\n<li>torch.bool</li>\n</ul>\n<p>默认都是用 float 类型，double 也不会增加什么好处。然后 tensor 可以作为其他 tensor 的索引，但是必须是 long 类型。<code>torch.tensor([2, 2])</code> 会给类型为 long 。需要注意的是 numpy 默认的浮点类型是 float64，而 tensor 默认的是 float32：</p>\n<p><img src=\"https://images-1300693298.cos.ap-beijing.myqcloud.com/%7B495D4F3D-FC9C-4F62-A9BA-25413B7B6A02%7D.png\" alt=\"\"></p>\n<h2 id=\"storage\" style=\"position:relative;\">Storage<a href=\"#storage\" aria-label=\"storage permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<p>每一个 tensor 的真是数据是由 <code>torch.Storage</code> 来维护的，它本质上就是一段连续的内存空间而已。Tensor 仅仅是为 storage 提供了 offset 和 stride 之后的视图而已。</p>\n<p><img src=\"https://images-1300693298.cos.ap-beijing.myqcloud.com/%7B4F5DC8FC-E908-408E-88C3-6FC09B95AF5E%7D.png\" alt=\"\"></p>\n<p>对于不同的 tensor 虽然它的 shape 不一样，但也可能指向了同一个的 storage。通过 tensor.storage() 可以直接访问它的内容：</p>\n<p><img src=\"https://images-1300693298.cos.ap-beijing.myqcloud.com/%7BFD54249D-DCFA-4437-905D-13F548279E5F%7D.png\" alt=\"\"></p>\n<p>不论 tensor 本身维度如何，其下的 storage 永远是一个一维数组。当然，修改 storage 的数据后，其 tensor 的数据也一定会发生变化。</p>\n<h2 id=\"size-offset-stride\" style=\"position:relative;\">size offset stride<a href=\"#size-offset-stride\" aria-label=\"size offset stride permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<ul>\n<li>offset 是 tensor 在 storage 的位置</li>\n<li>size 是当前 tensor 的维度</li>\n<li>stride 是这个 tensor 各个维度 +1 所需要跨越的 storage 索引个数</li>\n</ul>\n<p><img src=\"https://images-1300693298.cos.ap-beijing.myqcloud.com/%7B919B7731-CC39-45B5-897A-3A46180412C4%7D.png\" alt=\"\"></p>\n<p>那么当 tensor 本身发生了 transpose 之后，其实就是 size stride 发生了变化，其 storage 并没有变化的。</p>\n<h2 id=\"device-属性\" style=\"position:relative;\">device 属性<a href=\"#device-%E5%B1%9E%E6%80%A7\" aria-label=\"device 属性 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<p>tensor 创建时可以指定其属于什么设备：</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">points_gpu = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device='cuda')</code></pre></div>\n<p>默认是 cpu。</p>\n<p>当然也可以把 cpu 的 tensor 拷贝到 gpu：</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">points_gpu = points.to(device='cuda')</code></pre></div>\n<h2 id=\"和-numpy-相互转换\" style=\"position:relative;\">和 numpy 相互转换<a href=\"#%E5%92%8C-numpy-%E7%9B%B8%E4%BA%92%E8%BD%AC%E6%8D%A2\" aria-label=\"和 numpy 相互转换 permalink\" class=\"custom-class after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<p>只要都在主内存里，numpy array 和 tensor 之间的转换是非常高效的。那么这个好处就是可以享受 numpy 生态的各种类库。</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">points = torch.from_numpy(points_np)\npoints_np = points.numpy()</code></pre></div>","tableOfContents":"<ul>\n<li><a href=\"#%E6%9C%AC%E8%B4%A8\">本质</a></li>\n<li><a href=\"#%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B\">数据类型</a></li>\n<li><a href=\"#storage\">Storage</a></li>\n<li><a href=\"#size-offset-stride\">size offset stride</a></li>\n<li><a href=\"#device-%E5%B1%9E%E6%80%A7\">device 属性</a></li>\n<li><a href=\"#%E5%92%8C-numpy-%E7%9B%B8%E4%BA%92%E8%BD%AC%E6%8D%A2\">和 numpy 相互转换</a></li>\n</ul>","frontmatter":{"title":"pytorch tensors","date":"January 18, 2021"},"excerpt":"最近在都 Deep Learning with Pytorch 这本书，目前为止感觉还是不错。尤其…"}},"pageContext":{"id":"a5d4d343-341e-5e91-b175-13bd1fccb854"}},"staticQueryHashes":["4202924991"]}