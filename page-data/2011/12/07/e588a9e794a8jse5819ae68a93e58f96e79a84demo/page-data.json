{"componentChunkName":"component---src-templates-blog-js","path":"/2011/12/07/e588a9e794a8jse5819ae68a93e58f96e79a84demo/","result":{"data":{"blog":{"id":"fb28720d-5c1f-51dd-b273-0c1ae0540147","html":"<p>传统的爬虫模拟http请求获取页面没有办法模拟ajax请求，导致很多数据就难以获取。爬虫一直在试图把自己弄得像一个浏览器那样，可以处理各种诡异的情况。但是很遗憾，如果这个爬虫没有js解析的能力那怎么能够去处理ajax呢，如果爬虫不知道怎么渲染界面，它怎么知道什么元素是可见的，什么元素是不可见的呢。现在很多页面都是采用了前端脚本。乱七八糟的template里面是什么真正的数据都没有的。json里面的东西才是有意义的内容。所以，爬虫如果想完全处理那些问题，那它就要具备很多浏览器的功能了~</p>\n<p>但是，如果反过来怎么样呢？我们其实可以就用一个真真正正的浏览器去做这些工作的呀。我们可以让一个浏览器去模拟爬虫的抓取形式。当页面load完成后就可以获取页面的html内容了(innerHTML这样的东西)，然后检索整个页面上的合法Link 去一个个打开做递归...</p>\n<p>事实上，做爬虫很多时候就是想找到我们指定的一些数据。对页面里面很多乱七八糟的东西是没有兴趣的。可以只写js去定位一些元素里面的数据。当然，这会有很多的问题的。一个个打开，这样很慢的，效率是个问题。可是我觉得这的的确确是一个思路啊...</p>\n<p><a href=\"http://www.aisensiy.com/wp-content/uploads/2011/12/QQ%E6%88%AA%E5%9B%BE2011120719274111111111.png\"><img src=\"http://www.aisensiy.com/wp-content/uploads/2011/12/QQ%E6%88%AA%E5%9B%BE2011120719274111111111.png\" alt=\"\"></a></p>\n<p>这个控件里面是有ajax请求的，每次点击了一个城市，才会激发ajax请求获取数据。利用传统的方式，可能就要去找ajax的规律，然后利用规律一个个下载。但是我们用前端模拟点击事件，让页面自己按照常规的方式加载新的数据，然后从dom里面取到我们所需的内容就可以了</p>\n<p>这里我录了个屏，<a href=\"http://www.aisensiy.com/wp-content/uploads/2011/12/renren2.swf\">前端自动抓取demo</a>，由于尺寸比较大，就不插在文章里面了。请点击这个观看一段抓取的效果。当然，这仅仅是前端技术越发强大的冰山一角。我相信前端将会变得越发的强大以及越发的重要。</p>","tableOfContents":"","frontmatter":{"title":"利用JS做抓取的demo","date":"December 07, 2011"}}},"pageContext":{"id":"fb28720d-5c1f-51dd-b273-0c1ae0540147"}},"staticQueryHashes":[]}