---
author: aisensiy
comments: true
date: 2011-12-07 12:06:59+00:00
layout: post
slug: '%e5%88%a9%e7%94%a8js%e5%81%9a%e6%8a%93%e5%8f%96%e7%9a%84demo'
title: 利用JS做抓取的demo
wordpress_id: 160
categories:
- 关注web
---

传统的爬虫模拟http请求获取页面没有办法模拟ajax请求，导致很多数据就难以获取。爬虫一直在试图把自己弄得像一个浏览器那样，可以处理各种诡异的情况。但是很遗憾，如果这个爬虫没有js解析的能力那怎么能够去处理ajax呢，如果爬虫不知道怎么渲染界面，它怎么知道什么元素是可见的，什么元素是不可见的呢。现在很多页面都是采用了前端脚本。乱七八糟的template里面是什么真正的数据都没有的。json里面的东西才是有意义的内容。所以，爬虫如果想完全处理那些问题，那它就要具备很多浏览器的功能了~

但是，如果反过来怎么样呢？我们其实可以就用一个真真正正的浏览器去做这些工作的呀。我们可以让一个浏览器去模拟爬虫的抓取形式。当页面load完成后就可以获取页面的html内容了(innerHTML这样的东西)，然后检索整个页面上的合法Link 去一个个打开做递归...

事实上，做爬虫很多时候就是想找到我们指定的一些数据。对页面里面很多乱七八糟的东西是没有兴趣的。可以只写js去定位一些元素里面的数据。当然，这会有很多的问题的。一个个打开，这样很慢的，效率是个问题。可是我觉得这的的确确是一个思路啊...

[![](http://www.aisensiy.com/wp-content/uploads/2011/12/QQ%E6%88%AA%E5%9B%BE2011120719274111111111.png)](http://www.aisensiy.com/wp-content/uploads/2011/12/QQ%E6%88%AA%E5%9B%BE2011120719274111111111.png)

这个控件里面是有ajax请求的，每次点击了一个城市，才会激发ajax请求获取数据。利用传统的方式，可能就要去找ajax的规律，然后利用规律一个个下载。但是我们用前端模拟点击事件，让页面自己按照常规的方式加载新的数据，然后从dom里面取到我们所需的内容就可以了

这里我录了个屏，[前端自动抓取demo](http://www.aisensiy.com/wp-content/uploads/2011/12/renren2.swf)，由于尺寸比较大，就不插在文章里面了。请点击这个观看一段抓取的效果。当然，这仅仅是前端技术越发强大的冰山一角。我相信前端将会变得越发的强大以及越发的重要。
